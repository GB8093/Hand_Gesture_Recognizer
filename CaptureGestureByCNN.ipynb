{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e69ff38",
   "metadata": {},
   "source": [
    "#  Importing all required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2067a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import SGD, RMSprop, Adam\n",
    "\n",
    "from keras import backend as K\n",
    "if K.backend() == 'tensorflow':\n",
    "    import tensorflow\n",
    "else:\n",
    "    import theano\n",
    "    \n",
    "\n",
    "'''Ideally we should have changed image dim ordering based on Theano or Tensorflow, but for some reason I get following error when I switch it to 'tf' for Tensorflow.\n",
    "\tHowever, the outcome of the prediction doesnt seem to get affected due to this and Tensorflow gives me similar result as Theano.\n",
    "\tI didnt spend much time on this behavior, but if someone has answer to this then please do comment and let me know.\n",
    "    ValueError: Negative dimension size caused by subtracting 3 from 1 for 'conv2d_1/convolution' (op: 'Conv2D') with input shapes: [?,1,200,200], [3,3,200,32].\n",
    "'''\n",
    "    \n",
    "K.set_image_data_format('channels_first')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import cv2\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ee66a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input image dimensions\n",
    "img_rows, img_cols = 200, 200\n",
    "\n",
    "# number of channels\n",
    "# For grayscale use 1 value and for color images use 3 (R,G,B channels)\n",
    "img_channels = 1\n",
    "\n",
    "# Batch_size to train\n",
    "batch_size = 32\n",
    "\n",
    "## Number of output classes (change it accordingly)\n",
    "## eg: In my case I wanted to predict 4 types of gestures (Ok, Peace, Punch, Stop)\n",
    "## NOTE: If you change this then dont forget to change Labels accordingly\n",
    "nb_classes = 5\n",
    "\n",
    "# Number of epochs to train (change it accordingly)\n",
    "nb_epoch = 15  #25\n",
    "\n",
    "# Total number of convolutional filters to use\n",
    "nb_filters = 32\n",
    "# Max pooling\n",
    "nb_pool = 2\n",
    "# Size of convolution kernel\n",
    "nb_conv = 3\n",
    "\n",
    "\n",
    "#  data\n",
    "path = \"./\"\n",
    "path1 = \"./gestures\"    #path of folder of images\n",
    "\n",
    "## Path2 is the folder which is fed in to training model\n",
    "path2 = './trainingimgs'\n",
    "\n",
    "WeightFileName = []\n",
    "\n",
    "# outputs\n",
    "output = [\"OK\", \"NOTHING\",\"PEACE\", \"PUNCH\", \"STOP\"]\n",
    "\n",
    "\n",
    "jsonarray = {}\n",
    "\n",
    "\n",
    "def update(plot):\n",
    "    global jsonarray\n",
    "    h = 450\n",
    "    y = 30\n",
    "    w = 45\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    \n",
    "    for items in jsonarray:\n",
    "        mul = (jsonarray[items]) / 100\n",
    "        cv2.line(plot,(0,y),(int(h * mul),y),(255,0,0),w)\n",
    "        cv2.putText(plot,items,(0,y+5), font , 0.7,(0,255,0),2,1)\n",
    "        y = y + w + 30\n",
    "\n",
    "    return plot\n",
    "\n",
    "# For debug trace\n",
    "def debugme():\n",
    "    import pdb\n",
    "    pdb.set_trace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e0931",
   "metadata": {},
   "source": [
    "# Converting colour image to gray scale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b94fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function can be used for converting colored img to Grayscale img\n",
    "# while copying images from path1 to path2\n",
    "def convertToGrayImg(path1, path2):\n",
    "    listing = os.listdir(path1)\n",
    "    for file in listing:\n",
    "        if file.startswith('.'):\n",
    "            continue\n",
    "        img = Image.open(path1 +'/' + file)\n",
    "        #img = img.resize((img_rows,img_cols))\n",
    "        grayimg = img.convert('L')\n",
    "        grayimg.save(path2 + '/' +  file, \"PNG\")\n",
    "\n",
    "\n",
    "def modlistdir(path, pattern = None):\n",
    "    listing = os.listdir(path)\n",
    "    retlist = []\n",
    "    for name in listing:\n",
    "        #This check is to ignore any hidden files/folders\n",
    "        if pattern == None:\n",
    "            if name.startswith('.'):\n",
    "                continue\n",
    "            else:\n",
    "                retlist.append(name)\n",
    "        elif name.endswith(pattern):\n",
    "            retlist.append(name)\n",
    "            \n",
    "    return retlist\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2c5af9b",
   "metadata": {},
   "source": [
    "# Load CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6ea2b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CNN model\n",
    "def loadCNN(bTraining = False):\n",
    "    global get_output\n",
    "    model = Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv),\n",
    "                        padding='valid',\n",
    "                        input_shape=(img_channels, img_rows, img_cols)))\n",
    "    convout1 = Activation('relu')\n",
    "    model.add(convout1)\n",
    "    model.add(Conv2D(nb_filters, (nb_conv, nb_conv)))\n",
    "    convout2 = Activation('relu')\n",
    "    model.add(convout2)\n",
    "    model.add(MaxPooling2D(pool_size=(nb_pool, nb_pool)))\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    #sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adadelta', metrics=['accuracy'])\n",
    "    \n",
    "    # Model summary\n",
    "    model.summary()\n",
    "    # Model conig details\n",
    "    model.get_config()\n",
    "    \n",
    "    if not bTraining :\n",
    "        #List all the weight files available in current directory\n",
    "        WeightFileName = modlistdir('.','.hdf5')\n",
    "        if len(WeightFileName) == 0:\n",
    "            print('Error: No pretrained weight file found. Please either train the model or download one from the https://github.com/asingh33/CNNGestureRecognizer')\n",
    "            return 0\n",
    "        else:\n",
    "            print('Found these weight files - {}'.format(WeightFileName))\n",
    "        #Load pretrained weights\n",
    "        w = int(input(\"Which weight file to load (enter the INDEX of it, which starts from 0): \"))\n",
    "        fname = WeightFileName[int(w)]\n",
    "        print(\"loading \", fname)\n",
    "        model.load_weights(fname)\n",
    "\n",
    "    # refer the last layer here\n",
    "    layer = model.layers[-1]\n",
    "    get_output = K.function([model.layers[0].input, K.learning_phase()], [layer.output,])\n",
    "    \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c7aee5",
   "metadata": {},
   "source": [
    "#  Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0b641d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function does the guessing work based on input images\n",
    "def guessGesture(model, img):\n",
    "    global output, get_output, jsonarray\n",
    "    #Load image and flatten it\n",
    "    image = np.array(img).flatten()\n",
    "    \n",
    "    # reshape it\n",
    "    image = image.reshape(img_channels, img_rows,img_cols)\n",
    "    \n",
    "    # float32\n",
    "    image = image.astype('float32') \n",
    "    \n",
    "    # normalize it\n",
    "    image = image / 255\n",
    "    \n",
    "    # reshape for NN\n",
    "    rimage = image.reshape(1, img_channels, img_rows, img_cols)\n",
    "    \n",
    "    # Now feed it to the NN, to fetch the predictions\n",
    "    \n",
    "    prob_array = get_output([rimage, 0])[0]\n",
    "    \n",
    "    d = {}\n",
    "    i = 0\n",
    "    for items in output:\n",
    "        d[items] = prob_array[0][i] * 100\n",
    "        i += 1\n",
    "    \n",
    "    # Get the output with maximum probability\n",
    "    import operator\n",
    "    \n",
    "    guess = max(d.items(), key=operator.itemgetter(1))[0]\n",
    "    prob  = d[guess]\n",
    "\n",
    "    if prob > 60.0:\n",
    "        jsonarray = d\n",
    "                \n",
    "        return output.index(guess)\n",
    "\n",
    "    else:\n",
    "        # Lets return index 1 for 'Nothing' \n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba699da",
   "metadata": {},
   "source": [
    "#  Model creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c676a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initializers():\n",
    "    imlist = modlistdir(path2)\n",
    "    \n",
    "    image1 = np.array(Image.open(path2 +'/' + imlist[0])) # open one image to get size\n",
    "    #plt.imshow(im1)\n",
    "    \n",
    "    m,n = image1.shape[0:2] # get the size of the images\n",
    "    total_images = len(imlist) # get the 'total' number of images\n",
    "    \n",
    "    # create matrix to store all flattened images\n",
    "    immatrix = np.array([np.array(Image.open(path2+ '/' + images).convert('L')).flatten()\n",
    "                         for images in sorted(imlist)], dtype = 'f')\n",
    "    \n",
    "\n",
    "    \n",
    "    print(immatrix.shape)\n",
    "    \n",
    "    input(\"Press any key\")\n",
    "    \n",
    "\n",
    "    ## Label the set of images per respective gesture type.\n",
    "    label=np.ones((total_images,),dtype = int)\n",
    "    \n",
    "    samples_per_class = int(total_images / nb_classes)\n",
    "    print(\"samples_per_class - \",samples_per_class)\n",
    "    s = 0\n",
    "    r = samples_per_class\n",
    "    for classIndex in range(nb_classes):\n",
    "        label[s:r] = classIndex\n",
    "        s = r\n",
    "        r = s + samples_per_class\n",
    "    \n",
    "    '''\n",
    "    # eg: For 301 img samples/gesture for 4 gesture types\n",
    "    label[0:301]=0\n",
    "    label[301:602]=1\n",
    "    label[602:903]=2\n",
    "    label[903:]=3\n",
    "    '''\n",
    "    \n",
    "    data,Label = shuffle(immatrix,label, random_state=2)\n",
    "    train_data = [data,Label]\n",
    "     \n",
    "    (X, y) = (train_data[0],train_data[1])\n",
    "     \n",
    "     \n",
    "    # Split X and y into training and testing sets\n",
    "     \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=4)\n",
    "     \n",
    "    X_train = X_train.reshape(X_train.shape[0], img_channels, img_rows, img_cols)\n",
    "    X_test = X_test.reshape(X_test.shape[0], img_channels, img_rows, img_cols)\n",
    "     \n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "     \n",
    "    # normalize\n",
    "    X_train /= 255\n",
    "    X_test /= 255\n",
    "     \n",
    "    # convert class vectors to binary class matrices\n",
    "    Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "    Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1369b763",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7784e337",
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainModel(model):\n",
    "\n",
    "    # Split X and y into training and testing sets\n",
    "    X_train, X_test, Y_train, Y_test = initializers()\n",
    "\n",
    "    # Now start the training of the loaded model\n",
    "    hist = model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch,\n",
    "                 verbose=1, validation_split=0.2)\n",
    "\n",
    "    ans = input(\"Do you want to save the trained weights - y/n ?\")\n",
    "    if ans == 'y':\n",
    "        filename = input(\"Enter file name - \")\n",
    "        fname = path + str(filename) + \".hdf5\"\n",
    "        model.save_weights(fname,overwrite=True)\n",
    "    else:\n",
    "        model.save_weights(\"newWeight.hdf5\",overwrite=True)\n",
    "        \n",
    "    visualizeHis(hist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1636b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeHis(hist):\n",
    "    # visualizing losses and accuracy\n",
    "    keylist = hist.history.keys()\n",
    "    #print(hist.history.keys())\n",
    "    train_loss=hist.history['loss']\n",
    "    val_loss=hist.history['val_loss']\n",
    "    \n",
    "    #Tensorflow new updates seem to have different key name\n",
    "    if 'acc' in keylist:\n",
    "        train_acc=hist.history['acc']\n",
    "        val_acc=hist.history['val_acc']\n",
    "    else:\n",
    "        train_acc=hist.history['accuracy']\n",
    "        val_acc=hist.history['val_accuracy']\n",
    "    xc=range(nb_epoch)\n",
    "\n",
    "    plt.figure(1,figsize=(7,5))\n",
    "    plt.plot(xc,train_loss)\n",
    "    plt.plot(xc,val_loss)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('loss')\n",
    "    plt.title('train_loss vs val_loss')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'])\n",
    "    #print plt.style.available # use bmh, classic,ggplot for big pictures\n",
    "    #plt.style.use(['classic'])\n",
    "\n",
    "    plt.figure(2,figsize=(7,5))\n",
    "    plt.plot(xc,train_acc)\n",
    "    plt.plot(xc,val_acc)\n",
    "    plt.xlabel('num of Epochs')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.title('train_acc vs val_acc')\n",
    "    plt.grid(True)\n",
    "    plt.legend(['train','val'],loc=4)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf5b4684",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeLayers(model):\n",
    "    imlist = modlistdir('./imgs')\n",
    "    if len(imlist) == 0:\n",
    "        print('Error: No sample image file found under \\'./imgs\\' folder.')\n",
    "        return\n",
    "    else:\n",
    "        print('Found these sample image files - {}'.format(imlist))\n",
    "\n",
    "    img = int(input(\"Which sample image file to load (enter the INDEX of it, which starts from 0): \"))\n",
    "    layerIndex = int(input(\"Enter which layer to visualize. Enter -1 to visualize all layers possible: \"))\n",
    "    \n",
    "    if img <= len(imlist):\n",
    "        \n",
    "        image = np.array(Image.open('./imgs/' + imlist[img]).convert('L')).flatten()\n",
    "        \n",
    "        ## Predict\n",
    "        print('Guessed Gesture is {}'.format(output[guessGesture(model,image)]))\n",
    "        \n",
    "        # reshape it\n",
    "        image = image.reshape(img_channels, img_rows,img_cols)\n",
    "        \n",
    "        # float32\n",
    "        image = image.astype('float32')\n",
    "        \n",
    "        # normalize it\n",
    "        image = image / 255\n",
    "        \n",
    "        # reshape for NN\n",
    "        input_image = image.reshape(1, img_channels, img_rows, img_cols)\n",
    "    else:\n",
    "        print('Wrong file index entered !!')\n",
    "        return\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    if layerIndex >= 1:\n",
    "        visualizeLayer(model,img,input_image, layerIndex)\n",
    "    else:\n",
    "        tlayers = len(model.layers[:])\n",
    "        print(\"Total layers - {}\".format(tlayers))\n",
    "        for i in range(1,tlayers):\n",
    "             visualizeLayer(model,img, input_image,i)\n",
    "\n",
    "\n",
    "def visualizeLayer(model, img, input_image, layerIndex):\n",
    "\n",
    "    layer = model.layers[layerIndex]\n",
    "    \n",
    "    get_activations = K.function([model.layers[0].input, K.learning_phase()], [layer.output,])\n",
    "    activations = get_activations([input_image, 0])[0]\n",
    "    output_image = activations\n",
    "    \n",
    "    \n",
    "    ## If 4 dimensional then take the last dimension value as it would be no of filters\n",
    "    if output_image.ndim == 4:\n",
    "        output_image = np.moveaxis(output_image, 1, 3)\n",
    "        \n",
    "        print(\"Dumping filter data of layer{} - {}\".format(layerIndex,layer.__class__.__name__))\n",
    "        filters = len(output_image[0,0,0,:])\n",
    "        \n",
    "        fig=plt.figure(figsize=(8,8))\n",
    "        # This loop will plot the 32 filter data for the input image\n",
    "        for i in range(filters):\n",
    "            ax = fig.add_subplot(6, 6, i+1)\n",
    "            ax.imshow(output_image[0,:,:,i],'gray')\n",
    "            plt.xticks(np.array([]))\n",
    "            plt.yticks(np.array([]))\n",
    "        plt.tight_layout()\n",
    "        savedfilename = \"img_\" + str(img) + \"_layer\" + str(layerIndex)+\"_\"+layer.__class__.__name__+\".png\"\n",
    "        fig.savefig(savedfilename)\n",
    "        print(\"Create file - {}\".format(savedfilename))\n",
    "    else:\n",
    "        print(\"Can't dump data of this layer{}- {}\".format(layerIndex, layer.__class__.__name__))\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
